{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RankingDayNum</th>\n",
       "      <th>SystemName</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>OrdinalRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3492315</th>\n",
       "      <td>2018</td>\n",
       "      <td>133</td>\n",
       "      <td>ZAM</td>\n",
       "      <td>1460</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492316</th>\n",
       "      <td>2018</td>\n",
       "      <td>133</td>\n",
       "      <td>ZAM</td>\n",
       "      <td>1461</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492317</th>\n",
       "      <td>2018</td>\n",
       "      <td>133</td>\n",
       "      <td>ZAM</td>\n",
       "      <td>1462</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492318</th>\n",
       "      <td>2018</td>\n",
       "      <td>133</td>\n",
       "      <td>ZAM</td>\n",
       "      <td>1463</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492319</th>\n",
       "      <td>2018</td>\n",
       "      <td>133</td>\n",
       "      <td>ZAM</td>\n",
       "      <td>1464</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Season  RankingDayNum SystemName  TeamID  OrdinalRank\n",
       "3492315    2018            133        ZAM    1460          132\n",
       "3492316    2018            133        ZAM    1461           95\n",
       "3492317    2018            133        ZAM    1462           14\n",
       "3492318    2018            133        ZAM    1463          216\n",
       "3492319    2018            133        ZAM    1464          328"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "   \n",
    "tourney_df = pd.read_csv(\"data/MasseyOrdinals.csv\")\n",
    "tourney_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Season', 'Daynum', 'Wteam', 'Wscore', 'Lteam', 'Lscore', 'Wloc',\n",
       "       'Numot', 'team0Win', 'team0',\n",
       "       ...\n",
       "       'WMR1', 'PPR1', 'MPI1', 'STS1', 'UPS1', 'SPR1', 'MvG1', 'TRK1', 'BWE1',\n",
       "       'tourneylike'],\n",
       "      dtype='object', length=277)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourney_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_df = tourney_df.fillna(-1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Features to Use for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only execute one of following two cells\n",
    "\n",
    "Use first cell to use all the features available in the submission file.  After running through notebook once, can look at best features found by random forest and edit this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = ['SAG', 'MOR', 'WLK', 'POM', 'DOL', 'RPI', 'DOK', 'PGH']\n",
    "teamfList = systems\n",
    "featureList = []\n",
    "for f in teamfList:\n",
    "    featureList.append(f+'0')\n",
    "    featureList.append(f+'1')\n",
    "featureList = ['ACU0', 'BBT0', 'BWE0', 'DOK0', 'KPK0', 'MAS0', 'MOR0', 'PGH0', 'PIG0', 'POM0', 'RTP0', 'SAG0', 'TRK0', 'TRP0', 'WIL0', 'DII0', 'BIH0', 'WLK0', '7OT0', 'BUR0', 'DOL0', 'NOL0', 'SFX0', 'BOB0', 'COL0', 'CRO0', 'EBP0', 'MSX0', 'RTR0', 'SP0', 'TPR0', 'BLS0', 'CNG0', 'RTH0', 'SPR0', 'WOL0', 'DCI0', 'KRA0', 'LMC0', 'REW0', 'SEL0', 'SPW0', 'WOB0', 'ARG0', 'DC0', 'STH0', 'RPI0', 'HKB0', 'ACU1', 'BBT1', 'BWE1', 'DOK1', 'KPK1', 'MAS1', 'MOR1', 'PGH1', 'PIG1', 'POM1', 'RTP1', 'SAG1', 'TRK1', 'TRP1', 'WIL1', 'DII1', 'BIH1', 'WLK1', '7OT1', 'BUR1', 'DOL1', 'NOL1', 'SFX1', 'BOB1', 'COL1', 'CRO1', 'EBP1', 'MSX1', 'RTR1', 'SP1', 'TPR1', 'BLS1', 'CNG1', 'RTH1', 'SPR1', 'WOL1', 'DCI1', 'KRA1', 'LMC1', 'REW1', 'SEL1', 'SPW1', 'WOB1', 'ARG1', 'DC1', 'STH1', 'RPI1', 'HKB1', 'tourneylike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACU0', 'BBT0', 'BWE0', 'DOK0', 'KPK0', 'MAS0', 'MOR0', 'PGH0', 'PIG0', 'POM0', 'RTP0', 'SAG0', 'TRK0', 'TRP0', 'WIL0', 'DII0', 'BIH0', 'WLK0', '7OT0', 'BUR0', 'DOL0', 'NOL0', 'SFX0', 'BOB0', 'COL0', 'CRO0', 'EBP0', 'MSX0', 'RTR0', 'SP0', 'TPR0', 'BLS0', 'CNG0', 'RTH0', 'SPR0', 'WOL0', 'DCI0', 'KRA0', 'LMC0', 'REW0', 'SEL0', 'SPW0', 'WOB0', 'ARG0', 'DC0', 'STH0', 'RPI0', 'HKB0', 'ACU1', 'BBT1', 'BWE1', 'DOK1', 'KPK1', 'MAS1', 'MOR1', 'PGH1', 'PIG1', 'POM1', 'RTP1', 'SAG1', 'TRK1', 'TRP1', 'WIL1', 'DII1', 'BIH1', 'WLK1', '7OT1', 'BUR1', 'DOL1', 'NOL1', 'SFX1', 'BOB1', 'COL1', 'CRO1', 'EBP1', 'MSX1', 'RTR1', 'SP1', 'TPR1', 'BLS1', 'CNG1', 'RTH1', 'SPR1', 'WOL1', 'DCI1', 'KRA1', 'LMC1', 'REW1', 'SEL1', 'SPW1', 'WOB1', 'ARG1', 'DC1', 'STH1', 'RPI1', 'HKB1', 'tourneylike']\n"
     ]
    }
   ],
   "source": [
    "print(featureList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tourney_df['team0Win'].values # results\n",
    "X = tourney_df[featureList].values # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 277)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testyears = [2012,2013,2014,2015]\n",
    "mask = tourney_df['Season'] == testyears[0]\n",
    "for yr in testyears[1:]:\n",
    "    mask = mask | (tourney_df['Season'] == yr)\n",
    "mask = mask & (tourney_df['TourneyGame'] == 1)\n",
    "tourney_df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = tourney_df[mask]\n",
    "df_train = tourney_df[np.logical_not(mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['team0Win'].values # results\n",
    "X_train = df_train[featureList].values # features\n",
    "y_test = df_test['team0Win'].values # results\n",
    "X_test = df_test[featureList].values # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00000000e+06,  7.00000000e+00, -1.00000000e+06, ...,\n",
       "         2.00000000e+00,  1.00000000e+00,  1.14348551e+00],\n",
       "       [ 2.00000000e+00,  3.00000000e+00,  2.00000000e+00, ...,\n",
       "         6.00000000e+00,  7.00000000e+00,  1.13772183e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         4.00000000e+00,  2.00000000e+00,  1.13421161e+00],\n",
       "       ...,\n",
       "       [-1.00000000e+06,  2.19000000e+02, -1.00000000e+06, ...,\n",
       "         2.39000000e+02, -1.00000000e+06, -2.21273645e-01],\n",
       "       [-1.00000000e+06,  1.84000000e+02, -1.00000000e+06, ...,\n",
       "         1.89000000e+02,  1.87000000e+02, -2.46083508e-01],\n",
       "       [-1.00000000e+06,  2.22000000e+02, -1.00000000e+06, ...,\n",
       "         2.87000000e+02, -1.00000000e+06, -4.39167082e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=X_train.shape[0] #Number of training examples to use\n",
    "X_train_sample = X_train[0:size]\n",
    "y_train_sample = y_train[0:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "space ={\n",
    "        'max_depth': hp.randint('x_max_depth',  20),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.8, 1),\n",
    "        'scale_pos_weight': hp.uniform(\"x_pos_weight\", 1, 15),\n",
    "        \"learning_rate\":hp.uniform(\"x_learning_rate\",0.0003,0.003),\n",
    "        'colsample_bytree': hp.uniform ('x_tree_colsample', 0.4,1),\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test, y_test)\n",
    "def objective(space):\n",
    "\n",
    "    clf = XGBClassifier(n_estimators = 100, \n",
    "                            max_depth = space['max_depth'], \n",
    "                            min_child_weight =space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                            colsample_bytree =space['colsample_bytree'],\n",
    "                            learning_rate = space['learning_rate'], seed = 0)\n",
    "    \n",
    "    params = clf.get_xgb_params()\n",
    "    #dtest\n",
    "    score = xgb.cv(params, dtrain, nfold = 5, metrics = \"logloss\", early_stopping_rounds=10)\n",
    "    print(score)\n",
    "    #score = cross_val_score(clf, trainX, trainY, cv = 5, scoring=\"average_precision\")\n",
    "    \n",
    "    bst = xgb.train(params, dtrain)\n",
    "    preds = bst.predict(dtest)\n",
    "    test_score = metrics.log_loss(y_test, preds)\n",
    "    \n",
    "    print(\"HOLDOUT SCORE\", test_score)\n",
    "\n",
    "    return{'loss':1-test_score, 'status': STATUS_OK, \"holdout\":test_score }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT SCORE                                       \n",
      "0.6877941473651288                                  \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6931380742966239                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.690360869489499                                                            \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6923826997404667                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6913291344891733                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6931349136936131                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6918034820414302                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6885500416826846                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6914344587877616                                                           \n",
      "HOLDOUT SCORE                                                                \n",
      "0.6904527749588241                                                           \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6878219902960222                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6885139784261362                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6891702433575445                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6886823344141689                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6893071570058367                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6898111629841933                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6897837806548646                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6898041692242693                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6919193098794169                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6918586270133061                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6931423422560763                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6931428491179623                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6923924466567253                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6916923189341132                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.6925344111314461                                                            \n",
      "HOLDOUT SCORE                                                                 \n",
      "0.693145904968034                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6876285767822123                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6931457632957999                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6931458273485526                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6931454648277653                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6888208124619811                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6875587668436677                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6890731885362027                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.689642199162227                                                              \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6920738842949938                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6931453718623118                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6931457116977492                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.693146294622279                                                              \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6904818769266357                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6910833042504182                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6894704561624954                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6900848457172736                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6880786383329932                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6908160003263559                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6880431975891341                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6892690382786651                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6893053008104438                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6885386787688554                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6909460505442833                                                             \n",
      "HOLDOUT SCORE                                                                  \n",
      "0.6879002015982101                                                             \n",
      "100%|██████████| 50/50 [01:07<00:00,  1.38s/it, best loss: 0.30685370537772105]\n",
      "Optimization Time: %f seconds 67.46418595314026\n",
      "CPU times: user 1min 7s, sys: 457 ms, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trials = Trials()\n",
    "import time\n",
    "start = time.time()\n",
    "best = fmin(fn=objective, space = space, algo = tpe.suggest, max_evals = 50, trials = trials)\n",
    "end = time.time()\n",
    "print(\"Optimization Time: %f seconds\", (end  -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_learning_rate': 0.002050596297567944,\n",
       " 'x_max_depth': 0,\n",
       " 'x_min_child': 8.0,\n",
       " 'x_pos_weight': 4.730737378579532,\n",
       " 'x_subsample': 0.836933526126366,\n",
       " 'x_tree_colsample': 0.5831213255266434}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.693179+5.15364e-06\ttest-logloss:0.693156+1.90641e-05\n",
      "[1]\ttrain-logloss:0.693164+1.0012e-05\ttest-logloss:0.693168+3.74091e-05\n",
      "[2]\ttrain-logloss:0.693183+1.06132e-05\ttest-logloss:0.693181+5.551e-05\n",
      "[3]\ttrain-logloss:0.693212+3.27084e-05\ttest-logloss:0.693195+7.49256e-05\n",
      "[4]\ttrain-logloss:0.6932+2.32241e-05\ttest-logloss:0.693217+9.78844e-05\n",
      "[5]\ttrain-logloss:0.693254+2.83238e-05\ttest-logloss:0.693234+0.000114052\n",
      "[6]\ttrain-logloss:0.693241+5.03929e-05\ttest-logloss:0.693255+0.000130534\n",
      "[7]\ttrain-logloss:0.693275+2.57527e-05\ttest-logloss:0.693277+0.000155688\n",
      "[8]\ttrain-logloss:0.693312+3.85456e-05\ttest-logloss:0.693304+0.000171146\n",
      "[9]\ttrain-logloss:0.693325+4.65334e-05\ttest-logloss:0.693326+0.000191458\n",
      "   train-logloss-mean  train-logloss-std  test-logloss-mean  test-logloss-std\n",
      "0            0.693179           0.000005           0.693156          0.000019\n",
      "1            0.693164           0.000010           0.693168          0.000037\n",
      "2            0.693183           0.000011           0.693181          0.000056\n",
      "3            0.693212           0.000033           0.693195          0.000075\n",
      "4            0.693200           0.000023           0.693217          0.000098\n",
      "5            0.693254           0.000028           0.693234          0.000114\n",
      "6            0.693241           0.000050           0.693255          0.000131\n",
      "7            0.693275           0.000026           0.693277          0.000156\n",
      "8            0.693312           0.000039           0.693304          0.000171\n",
      "9            0.693325           0.000047           0.693326          0.000191\n",
      "0.4962686567164179\n"
     ]
    }
   ],
   "source": [
    "best_xgbc = XGBClassifier(n_estimators=100, scale_pos_weight=best[\"x_pos_weight\"],\n",
    "                         learning_rate = best[\"x_learning_rate\"], \n",
    "                         max_depth = int(best[\"x_max_depth\"]), \n",
    "                         min_child_weight = best[\"x_min_child\"],\n",
    "                         subsample = best[\"x_subsample\"], \n",
    "                         colsample_bytree = best[\"x_tree_colsample\"])\n",
    "params = best_xgbc.get_xgb_params()\n",
    "score = xgb.cv(params, dtrain, nfold = 5, metrics = \"logloss\", verbose_eval=True)\n",
    "print(score)\n",
    "bst = xgb.train(params, dtrain)\n",
    "preds = bst.predict(dtest)\n",
    "score = metrics.average_precision_score(y_test, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss is 0.7304882416084632\n"
     ]
    }
   ],
   "source": [
    "best_xgbc.fit(X_train, y_train)\n",
    "y_pred = best_xgbc.predict_proba(X_test) # probability that team0 wins (what Kaggle calls team 1, and wants for submission)\n",
    "from sklearn import metrics\n",
    "test_score = metrics.log_loss(y_test, y_pred)\n",
    "print(\"Log loss is {0}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [1000], 'max_features': ['sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_s = StratifiedShuffleSplit(n_splits=10 , test_size=0.1, random_state=42)\n",
    "rfc = RandomForestClassifier(max_features= 'auto' ,n_estimators=50) \n",
    "param_grid = { \n",
    "        'n_estimators': [1000],\n",
    "        'max_features': ['sqrt']}\n",
    "CV_rfc = GridSearchCV(n_jobs=-1, estimator=rfc, scoring=\"neg_log_loss\", param_grid=param_grid, cv=cv_s)\n",
    "CV_rfc.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {{'max_features': 'sqrt', 'n_estimators': 1000}} with a score of -0.5866\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters are {%s} with a score of %0.4f\" % (CV_rfc.best_params_, CV_rfc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss is 0.5776264925658652\n"
     ]
    }
   ],
   "source": [
    "model = CV_rfc.best_estimator_\n",
    "y_pred = model.predict_proba(X_test) # probability that team0 wins (what Kaggle calls team 1, and wants for submission)\n",
    "from sklearn import metrics\n",
    "test_score = metrics.log_loss(y_test, y_pred)\n",
    "print(\"Log loss is {0}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68656716417910446"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 7 POM1 (0.072302)\n",
      "2. feature 10 RPI0 (0.069910)\n",
      "3. feature 4 WLK0 (0.067345)\n",
      "4. feature 6 POM0 (0.066720)\n",
      "5. feature 5 WLK1 (0.064850)\n",
      "6. feature 0 SAG0 (0.064251)\n",
      "7. feature 12 DOK0 (0.063912)\n",
      "8. feature 13 DOK1 (0.063283)\n",
      "9. feature 3 MOR1 (0.063236)\n",
      "10. feature 2 MOR0 (0.062223)\n",
      "11. feature 11 RPI1 (0.060458)\n",
      "12. feature 1 SAG1 (0.060014)\n",
      "13. feature 9 DOL1 (0.059860)\n",
      "14. feature 8 DOL0 (0.056782)\n",
      "15. feature 14 PGH0 (0.052667)\n",
      "16. feature 15 PGH1 (0.052187)\n"
     ]
    }
   ],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], tourney_df[featureList].columns[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128f4eb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "maxval = Nfeatures\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1])[:maxval], importances[indices][:maxval],\n",
    "       color=\"r\", yerr=std[indices][:maxval], align=\"center\")\n",
    "plt.xticks(range(X.shape[1])[:maxval], indices)\n",
    "plt.xlim([-1, maxval])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Write Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(model, featureList, submission_output_file): # see submission.ipynb for details\n",
    "    import pandas as pd\n",
    "    sample_df = pd.read_csv('data/2016SampleSubmissionWithFeatures.csv', index_col=0)\n",
    "    Xsample = sample_df[featureList].values\n",
    "    sample_df['Pred'] = model.predict_proba(Xsample)[:,1] # predict_proba returns [prob label is 0, prob label is 1], kaggle wants 2nd column\n",
    "    submission = sample_df[['Id', 'Pred']]\n",
    "    submission.to_csv(submission_output_file, encoding='ascii', index=False)\n",
    "submission_output_file = \"data/submissionRF6000.csv\"\n",
    "write_submission_file(model, featureList, submission_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016_1112_1114</th>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016_1112_1122</th>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016_1112_1124</th>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016_1112_1138</th>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016_1112_1139</th>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Pred\n",
       "Id                   \n",
       "2016_1112_1114  0.648\n",
       "2016_1112_1122  0.780\n",
       "2016_1112_1124  0.658\n",
       "2016_1112_1138  0.773\n",
       "2016_1112_1139  0.690"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv(submission_output_file, index_col=0)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
